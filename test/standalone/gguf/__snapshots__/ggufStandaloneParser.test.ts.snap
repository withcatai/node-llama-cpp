// Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html

exports[`gguf > parser > should parse remote gguf model 1`] = `
{
  "architectureMetadata": {
    "attention": {
      "head_count": 232,
      "head_count_kv": 8,
      "layer_norm_epsilon": 0.000009999999747378752,
    },
    "block_count": 80,
    "context_length": 2048,
    "embedding_length": 14848,
    "feed_forward_length": 59392,
    "tensor_data_layout": "jploski",
  },
  "fullTensorInfo": [
    {
      "dimensions": [
        14848,
        59392,
      ],
      "fileOffset": 2585504,
      "filePart": 1,
      "ggmlType": 14,
      "name": "blk.0.ffn_up.weight",
      "offset": 0,
    },
    {
      "dimensions": [
        14848,
        14848,
      ],
      "fileOffset": 725980064,
      "filePart": 1,
      "ggmlType": 14,
      "name": "blk.0.attn_output.weight",
      "offset": 723394560,
    },
    {
      "dimensions": [
        14848,
        15872,
      ],
      "fileOffset": 906828704,
      "filePart": 1,
      "ggmlType": 14,
      "name": "blk.0.attn_qkv.weight",
      "offset": 904243200,
    },
    {
      "dimensions": [
        14848,
        65024,
      ],
      "fileOffset": 1100149664,
      "filePart": 1,
      "ggmlType": 14,
      "name": "token_embd.weight",
      "offset": 1097564160,
    },
  ],
  "metadata": {
    "falcon": {
      "attention": {
        "head_count": 232,
        "head_count_kv": 8,
        "layer_norm_epsilon": 0.000009999999747378752,
      },
      "block_count": 80,
      "context_length": 2048,
      "embedding_length": 14848,
      "feed_forward_length": 59392,
      "tensor_data_layout": "jploski",
    },
    "general": {
      "architecture": "falcon",
      "file_type": 18,
      "name": "Falcon",
      "quantization_version": 2,
    },
    "tokenizer": {
      "ggml": {
        "eos_token_id": 11,
        "merges": [
          "Ġ t",
          "Ġ a",
          "i n",
          "h e",
          "r e",
          "o n",
          "e r",
          "Ġ s",
          "Ġt he",
          "a t",
        ],
        "model": "gpt2",
        "scores": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
        ],
        "token_type": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
        ],
        "tokens": [
          ">>TITLE<<",
          ">>ABSTRACT<<",
          ">>INTRODUCTION<<",
          ">>SUMMARY<<",
          ">>COMMENT<<",
          ">>ANSWER<<",
          ">>QUESTION<<",
          ">>DOMAIN<<",
          ">>PREFIX<<",
          ">>SUFFIX<<",
        ],
      },
    },
  },
  "metadataSize": 2547826,
  "splicedParts": 1,
  "tensorCount": 644,
  "tensorInfo": [
    {
      "dimensions": [
        14848,
        59392,
      ],
      "fileOffset": 2585504,
      "filePart": 1,
      "ggmlType": 14,
      "name": "blk.0.ffn_up.weight",
      "offset": 0,
    },
    {
      "dimensions": [
        14848,
        14848,
      ],
      "fileOffset": 725980064,
      "filePart": 1,
      "ggmlType": 14,
      "name": "blk.0.attn_output.weight",
      "offset": 723394560,
    },
    {
      "dimensions": [
        14848,
        15872,
      ],
      "fileOffset": 906828704,
      "filePart": 1,
      "ggmlType": 14,
      "name": "blk.0.attn_qkv.weight",
      "offset": 904243200,
    },
    {
      "dimensions": [
        14848,
        65024,
      ],
      "fileOffset": 1100149664,
      "filePart": 1,
      "ggmlType": 14,
      "name": "token_embd.weight",
      "offset": 1097564160,
    },
  ],
  "tensorInfoSize": 37648,
  "totalMetadataSize": 2547826,
  "totalTensorCount": 644,
  "totalTensorInfoSize": 37648,
  "version": 2,
}
`;

exports[`gguf > parser > should parse remote gguf model without tensor info 1`] = `
{
  "architectureMetadata": {
    "attention": {
      "head_count": 232,
      "head_count_kv": 8,
      "layer_norm_epsilon": 0.000009999999747378752,
    },
    "block_count": 80,
    "context_length": 2048,
    "embedding_length": 14848,
    "feed_forward_length": 59392,
    "tensor_data_layout": "jploski",
  },
  "fullTensorInfo": undefined,
  "metadata": {
    "falcon": {
      "attention": {
        "head_count": 232,
        "head_count_kv": 8,
        "layer_norm_epsilon": 0.000009999999747378752,
      },
      "block_count": 80,
      "context_length": 2048,
      "embedding_length": 14848,
      "feed_forward_length": 59392,
      "tensor_data_layout": "jploski",
    },
    "general": {
      "architecture": "falcon",
      "file_type": 18,
      "name": "Falcon",
      "quantization_version": 2,
    },
    "tokenizer": {
      "ggml": {
        "eos_token_id": 11,
        "merges": [
          "Ġ t",
          "Ġ a",
          "i n",
          "h e",
          "r e",
          "o n",
          "e r",
          "Ġ s",
          "Ġt he",
          "a t",
        ],
        "model": "gpt2",
        "scores": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
        ],
        "token_type": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
        ],
        "tokens": [
          ">>TITLE<<",
          ">>ABSTRACT<<",
          ">>INTRODUCTION<<",
          ">>SUMMARY<<",
          ">>COMMENT<<",
          ">>ANSWER<<",
          ">>QUESTION<<",
          ">>DOMAIN<<",
          ">>PREFIX<<",
          ">>SUFFIX<<",
        ],
      },
    },
  },
  "metadataSize": 2547826,
  "splicedParts": 1,
  "tensorCount": 644,
  "tensorInfo": undefined,
  "tensorInfoSize": undefined,
  "totalMetadataSize": 2547826,
  "totalTensorCount": 644,
  "totalTensorInfoSize": undefined,
  "version": 2,
}
`;
